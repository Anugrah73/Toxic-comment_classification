# Toxic-comment_classification
## Overview
The toxic comment classification project is an implementation of machine learning techniques to automatically classify and identify toxic comment in text data. The goal of this project is to develop a model that can distinguish between different types of toxic language, such as hate, speech, insults, threats, and offensive remarks. 
## Introduction
Online platforms often struggle with managing toxic content that can create a hostile environment. This project aims to provide a solution to this problem by using machine learning to automatically detect and classify toxic comments in text data. By developing an accurate classification model, we can enhance the user experience and promote healthy discussions within online communities. 
## Dataset
The dataset for this project is collected from Kaggle. It consist of comments labeled with different levels of toxicity including labels such as toxic, severe toxic, obscene, threat and insult. 
## Models
This project is using NLP(Natural Language Processing) model. There are several NLP models, and in this project, Neural Network model is used. 
## Evaluation 
The models are evaluated using variety of metrics to determine their effectiveness in classifying toxic comments. 
## Deployment
To deploy the toxic comment classification model, we utilize an interface where users can input text and recieve predictions on the toxicity level of their comments. We use Gradio to create that interface. Gradio app enables to share this project with others.

